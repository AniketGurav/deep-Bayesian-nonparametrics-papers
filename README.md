# deep-Bayesian-nonparametrics
*The collection of papers about combining deep learning with Bayesian nonparametrics*

  We made a concise name "deep Bayesian non-parametrics"(DBNP) to a series of work bringing the fields of deep learning and Bayesian non-parametrics together. Generally, not only DBNP means combining the neural networks with stochastic processes in Bayesian modelling, but also leveraging common and effective structures designed in deep learning, such as convolution, recurrence and deep hierachies, in Bayesian non-parameterics setting. Meanwhile, corresponding training methods designed for these models, especially approximate inference, are also our concerns.   
  
### Deep Gaussain Process Models and Inference Algorithms
1. [Deep Gaussian Processes](https://arxiv.org/abs/1211.0358)
2. [Nested Variational Compression in Deep Gaussian Processes](https://arxiv.org/abs/1412.1370)
3. [Training Deep Gaussian Processes using Stochastic Expectation Propagation and Probabilistic Backpropagation](https://arxiv.org/abs/1511.03405)
4. [Variational Auto-encoded Deep Gaussian Processes](https://arxiv.org/abs/1511.06455) 
5. [Deep Gaussian Processes for Regression using Approximate Expectation Propagation](https://arxiv.org/abs/1602.04133)
6. [Random Feature Expansions for Deep Gaussian Processes](https://arxiv.org/abs/1610.04386) 
7. [Doubly Stochastic Variational Inference for Deep Gaussian Processes](https://arxiv.org/abs/1705.08933) 
8. [Deep Gaussian Processes with Decoupled Inducing Inputs](https://arxiv.org/abs/1801.02939)
9. [Deep Gaussian Processes with Convolutional Kernels](https://arxiv.org/abs/1806.01655)
10. [Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo](https://arxiv.org/abs/1806.05490)

### 
1. [Recurrent Gaussian Processes](https://arxiv.org/abs/1511.06644)
2. [Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation](https://arxiv.org/abs/1711.00799)
